---
title: "Seascape Ecology"
subtitle: "Lab 07 - Data Sources"
author: "Ryan Reisinger"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

Today we'll take a look at some some ways to get environmental data for your seascape analyses. These are only a few options, there are many out there; finding them requires a bit of research: Google and patience are your friends. Also, keep an eye out for linked datasets in any papers you read.

This step can sometimes we difficult and frustrating. Go easy on yourself: stay patient and ask for help, from your classmates, me and Mark, or the internet.

Ask me and Mark about different datasets that you might want to use. Usually every new dataset requires a bit of 'wrangling' to get it to work.

# Bathymetry data

## Using the marmap package

Refer back to Lab 04 where you practiced using the `marmap` package (<https://cran.r-project.org/package=marmap>) to download bathymetry data. You could also download data manually from NOAA (<https://www.ngdc.noaa.gov/mgg/global/global.html>) or GEBCO (<https://www.gebco.net/>).

# Environmental data

## Copernicus Marine

<https://data.marine.copernicus.eu/products>

### How to work with files from Copernicus Marine

<https://marine.copernicus.eu/services/user-learning-services/using-r-work-copernicus-marine-data>

This tutorial by [David March](https://scholar.google.com/citations?user=xABsDpAAAAAJ&hl=en&oi=ao) has a step-by-step video and the associated materials are available at: <https://atlas.mercator-ocean.fr/s/dCTPqL77Ydposfi>. The NetCDF (`.nc`) file that David downloads (`download.file()` function) and then reads in (`nc_open()` function) is hosted on his Github page (and is also contained in the training materials), but is originally downloaded directly from Copernicus Marine. For example, you can look at all the products with a global spatial coverage at: <https://data.marine.copernicus.eu/products?facets=areas%7EGlobal+Ocean>

Once you have selected a data product you are interested in, click on the 'data access' button in the toolbar on the left, which will bring up several download options. You will need to register for a free account first. You could, for example, click on the 'FTP' link to access the folder and raw files directly using FTP (e.g., <ftp://nrt.cmems-du.eu/Core/GLOBAL_ANALYSISFORECAST_PHY_001_024/cmems_mod_glo_phy-cur_anfc_0.083deg_P1D-m>), or click on the 'MOTU' link to enter parameters (like spatial and temporal extent) and then download the resulting `.nc` file. You can explore the dataset visually by clicking on the map icon at top right.

[![Figure 1. Exploring a data product visually by clicking the on the map icon.](resources/Copernicus_screenshot.jpg)](Figure 1)

You could also explore and download products through their MyOcean Pro visualisation tool: <https://data.marine.copernicus.eu/viewer/expert>.

As David says in his tutorial, there is an R package called RCMEMS (<https://github.com/markpayneatwork/RCMEMS>) to download these files directly through R, but it is fairly complex to set up, since you need a Python installation on your machine.

Remember, you should read and understand the product overview (e.g., <https://data.marine.copernicus.eu/product/GLOBAL_ANALYSISFORECAST_PHY_001_024/description>) and you will need to give these details in a report (like your workflow assessment, see the marking rubric) or paper. You can cite the product using the DOI (for example, <https://doi.org/10.48670/moi-00016>).

Once you have worked through David's tutorial, try with your own data product that you choose from Copernicus Marine.

## NOAA

### ERDDAP

NOAA provides its gridded datasets through a server called [ERDDAP](https://upwell.pfeg.noaa.gov/erddap/index.html).

You can see the datasets (what we called 'products' above) here: <https://coastwatch.pfeg.noaa.gov/erddap/griddap/index.html?page=1&itemsPerPage=1000>. You can use that page to get the data by clicking the 'data' link in the leftmost column for a given product (the column is called 'Grid DAP Data'), choosing the temporal and spatial extent, selecting `.nc` in the file type dropdown, and then clicking 'Submit'. You can do an advanced search on the page to find what you're looking for (<https://coastwatch.pfeg.noaa.gov/erddap/search/advanced.html?page=1&itemsPerPage=1000&protocol=griddap>).

For example, I went to the search page, typed "chlorophyll global" in the "Full Text Search for Datasets" box, then clicked on the 'data' link for the result with this title: "Chlorophyll-a, Aqua MODIS, NPP, L3SMI, Global, 4km, R2022 NRT, 2003-present (Monthly Composite)". As for Copernicus Marine above, it's important to read the product details. You can get that information by clicking on the 'background' link in the 'Background Info' column. This link should take you directly to the product data access page: <https://coastwatch.pfeg.noaa.gov/erddap/griddap/erdMH1chlamday_R2022NRT.html> (and the background info. is at <https://oceandata.sci.gsfc.nasa.gov/>, but it's not so informative in this case).

Take note of the dataset ID found near the top of the page and also in the website URL: 'erdMH1chlamday_R2022NRT'. You can use this ID later in the `rerddap` package. I left the time dimension as-is, and I left the latitude and longitude as-is. This should give me the latest available global file. Select '.nc' in the File type dropdown, and click 'Submit'.

[![Figure 2. Screenshot of the ERDDAP download page.](resources/ERDDAP_screenshot.jpg)](Figure%202)

Be patient once you have clicked submit, it takes a while. This generates a pretty big file (\~150 MB) that you can download. You may wish to change the spatial extent (the latitude and longitude) so the download is smaller. I changed mine to -20 - +20 latitude and -10 - +10 longitude for this example.

Notice you can also generate a link by clicking 'Just generate the URL'. In my case this gave:

[`https://coastwatch.pfeg.noaa.gov/erddap/griddap/erdMH1chlamday_R2022NRT.nc?chlorophyll%5B(2022-11-16T00:00:00Z):1:(2022-11-16T00:00:00Z)%5D%5B(20):1:(-20)%5D%5B(-10):1:(+10)%5D`](https://coastwatch.pfeg.noaa.gov/erddap/griddap/erdMH1chlamday_R2022NRT.nc?chlorophyll%5B(2022-11-16T00:00:00Z):1:(2022-11-16T00:00:00Z)%5D%5B(20):1:(-20)%5D%5B(-10):1:(+10)%5D)

We can read the file into R using the `raster` package.

```{r}
library(raster)
library(terra)

chl <- raster::raster("./resources/erdMH1chlamday_R2022NRT_2b95_1e81_5998_U1670403378531.nc")

# Plot
plot(chl)

# We can convert this to a terra object
chl_terra <- rast(chl)

# Plot
plot(chl_terra)

# Upside down! So flip it:
chl_terra <- flip(chl_terra, direction = "vertical")
plot(chl_terra)

# We could also read it in directly from the URL:
my_file <- download.file(url = "https://coastwatch.pfeg.noaa.gov/erddap/griddap/erdMH1chlamday_R2022NRT.nc?chlorophyll%5B(2022-11-16T00:00:00Z):1:(2022-11-16T00:00:00Z)%5D%5B(20):1:(-20)%5D%5B(-10):1:(+10)%5D",
                         destfile = "./resources/my_chl.nc")

# And read it in
chl <- raster::raster("./resources/my_chl.nc")

foo <- terra::rast("./resources/my_chl.nc")

# Plot
plot(chl)
```

A more detailed tutorial is provided here:

<https://coastwatch.gitbook.io/satellite-course/tutorials/r-tutorial/1.-how-to-work-with-satellite-data-in-r>

We can get also get data from the ERDDAP server using the `rerddap` package (<https://docs.ropensci.org/rerddap/>). The CoastWatch tutorial above includes rerddap tutorials, and rerddap has two vignettes:

<https://cloud.r-project.org/web/packages/rerddap/vignettes/rerddap.html>

<https://cloud.r-project.org/web/packages/rerddap/vignettes/Using_rerddap.html>

There are also some general tutorials like the following:

<https://cran.r-project.org/web/packages/heatwaveR/vignettes/OISST_preparation.html>

### Ocean Color Data

<https://oceandata.sci.gsfc.nasa.gov/>

You can use the NASA Ocean Color L3 browser: <https://oceancolor.gsfc.nasa.gov/l3/>

# Other data sources

If you encounter a product you're interested in using, speak to me or Mark about how to access and use the data for your assessment.

# Practice

Start playing around with these data sources, and start thinking about what you want to do for your assessment. Mark and I will walk around to answer questions, and next week is a drop-in session where you can bring your ideas and/or datasets for help.
